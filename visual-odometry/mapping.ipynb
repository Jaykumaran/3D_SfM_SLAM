{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f60e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import time\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KNN Implementation\n",
    "\"\"\"\n",
    "def eucledianDistance(desc1, desc2):\n",
    "    distance = 0\n",
    "    for x in range(len(desc1)):\n",
    "        distance += pow(desc1[x] - desc2[x], 2)\n",
    "\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "# Eucledian distance matcher, custom/better version\n",
    "def EUBetter(desc1, desc2, distances, iteration):\n",
    "    desc1 = np.array(desc1)\n",
    "    desc2 = np.array(desc2)\n",
    "    \n",
    "    distance = desc1 - desc2\n",
    "    distance = np.power(distance, 2)\n",
    "    distance = np.sum(distance, axis = 1)\n",
    "    distance = np.sqrt(distance)\n",
    "    distance_indices = np.argsort(distance)\n",
    "    \n",
    "    k_match = []\n",
    "    for i in range(2):\n",
    "        k_match.append(cv2.DMatch(iteration, distance_indices[i], distance[distance_indices[i]]))\n",
    "    \n",
    "    return k_match\n",
    "\n",
    "def KNNMatch(desc1, desc2, k =2): # query, # train\n",
    "    matches = []\n",
    "    for i in range(len(desc1)):\n",
    "        distances = []\n",
    "        \n",
    "        t1 = time.time()\n",
    "        k_match = EUBetter(desc1[i], desc2, distances, i)\n",
    "        matches.append(k_match)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e05c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "class SfMSolver(object):\n",
    "    \n",
    "    def __init__(self, img_pattern, intrinsic, output_dir, downscale = 1):\n",
    "        \"\"\"   \n",
    "        img_pattern: regex pattern used by glob to read the files\n",
    "        \"\"\"\n",
    "        self.img_pattern = img_pattern\n",
    "        self.K_orig = self.intrinsic_orig = intrinsic.copy()\n",
    "        self.output_dir = output_dir\n",
    "        self.downscale = downscale\n",
    "        self.rescale_intrinsic()\n",
    "    \n",
    "    def rescale_intrinsic(self):\n",
    "        \"\"\" \n",
    "        if we downscale the image, the intrinsic matrix also need to be changed\"\"\"\n",
    "        \n",
    "        start = time.time()\n",
    "        # scale focal length and principal points w.r.t image processing\n",
    "        if self.downscale > 1:\n",
    "            self.K = self.K_orig.copy()\n",
    "            self.K[0, 0] /= float(self.downscale)\n",
    "            self.K[1, 1] /= float(self.downscale)\n",
    "            self.K[0, 2] /= float(self.downscale)\n",
    "            self.K[1, 2] /= float(self.downscale)\n",
    "            self.intrinsic = self.K\n",
    "        else:\n",
    "            self.K = self.intrinsic = self.K_orig.copy()\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "    def load_images(self):\n",
    "        \"\"\"  \n",
    "        Loads a set of images to self.imgs list\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        self.img_paths = sorted(glob(self.img_pattern))\n",
    "        self.imgs = []\n",
    "        for idx, img_path in enumerate(self.img_paths):\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if self.downscale > 1:\n",
    "                    img = cv2.resized(img, (0, 0), \n",
    "                                      fx = 1/float(self.downscale), fy= 1/float(self.downscale),\n",
    "                                      interpolation = cv2.INTER_LINEAR)\n",
    "            except Exception as e:\n",
    "                print(\"Error loading img: %s\" % (img_path))\n",
    "            \n",
    "            if img is not None:\n",
    "                self.imgs.append(img)\n",
    "                print(\"loaded img %d size=(%d, %d): %s\" % \n",
    "                      (idx, img.shape[0], img.shape[1], img_path))\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        \n",
    "    def visualize_matches(self, img1, img2,\n",
    "                          kp1, kp2, good, \n",
    "                          mask = None, save_path = None):\n",
    "        start = time.time()\n",
    "        draw_params = dict(matchColor = (0, 255, 0),\n",
    "                           singlePointColor = None,\n",
    "                           flags = 2)\n",
    "        if mask is not None:\n",
    "            if not isinstance(mask, list):\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "            else:\n",
    "                matchesMask = mask\n",
    "            draw_matches['matchesMask'] = matchesMask\n",
    "        img_matches = cv2.drawMatches(\n",
    "            img1, kp1, img2, kp2, good, None, **draw_params\n",
    "        )\n",
    "        cv2.imwrite(save_path, img_matches)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "    \n",
    "    def drawlines(self, img1, img2, lines, pts1, pts2, line_num = None):\n",
    "        \"\"\" \n",
    "        Draw line connecting points in two images\"\"\"\n",
    "        start = time.time()\n",
    "        if img1.ndim ==2:  # Gray\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "            r, c = img1.shape\n",
    "        else:  # 3\n",
    "            r, c, _ = img1.shape\n",
    "        if line_num is not None:\n",
    "            draw_list = np.random.choice(\n",
    "                pts1.shape[0], line_num, replace = False\n",
    "            )\n",
    "        else:\n",
    "            draw_list = np.arange(pts1.shape[0])\n",
    "        \n",
    "        for ifx, (r, pt1, pt2) in enumerate(zip(lines, pts1, pts2)):\n",
    "            if idx not in list(draw_list):\n",
    "                continue\n",
    "            color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "            x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "            x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "            \n",
    "            pt1_int = (int(tuple(pt1.ravel())[0]), int(tuple(pt1.ravel())[1]))\n",
    "            pt2_int = (int(tuple(pt2.ravel())[0]), int(tuple(pt2.ravel())[1]))\n",
    "            \n",
    "            img1 = cv2.line(img1, (int(x0), int(y0)), (int(x1), int(y1)), color, 1)\n",
    "            img1 = cv2.circle(img1, pt1_int, 5, color, -1)\n",
    "            img2 = cv2.circle(img2, pt2_int, 5, color, -1)\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return img1, img2\n",
    "    \n",
    "    \n",
    "    def visualize_epipolar_lines(self, img1, img2, p1, p2, E, save_path):\n",
    "        start = time.time()\n",
    "        # get fundamental matrix\n",
    "        F, mask_fdm = cv2.findFundamentalMat(p1, p2, cv2.RANSAC)\n",
    "        p1_selected = p1[mask_fdm.ravel() == 1]\n",
    "        p2_selected = p2[mask_fdm.ravel() == 1]\n",
    "        \n",
    "        # draw lines\n",
    "        lines1 = cv2.computeCorrespondEpilines(\n",
    "            p2_selected.reshape(-1, 1, 2), 2, F).reshape(-1, 3)\n",
    "        img5, _ = self.drawlines(\n",
    "            img1, img2, lines1, p1_selected, p2_selected, 100\n",
    "        )\n",
    "        \n",
    "        lines2= cv2.computeCorrespondEpilines(\n",
    "            p1_selected.reshape(-1, 1, 2), 1, F).reshape(-1, 3)\n",
    "        \n",
    "        img3, _ = self.drawlines(\n",
    "            img2, img1, lines2, p2_selected, p1_selected, 100\n",
    "        )\n",
    "        canvas = np.concatenate((img5, img3), axis = 1)\n",
    "        cv2.imwrite(save_path, canvas)\n",
    "        elapsed = time.time() - start\n",
    "    \n",
    "    def write_simple_obj(self, mesh_v, mesh_f, filepath, verbose = False):\n",
    "        \"\"\" \n",
    "        Saves 3D points which can be read in meshlab\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        with open(filepath, 'w') as fp:\n",
    "            for v in mesh_v:\n",
    "                fp.write('v %f %f %f\\n' % (v[0], v[1], v[2]))\n",
    "            if mesh_f is not None:\n",
    "                for f in mesh_f+1: # Faces are 1-based, not 0-based in obj files\n",
    "                    fp.write('f %d %d %d\\n' % (f[0], f[1], f[2]))\n",
    "        if verbose:\n",
    "            print('mesh saved to: ', filepath)\n",
    "        elapsed = time.time()\n",
    "    \n",
    "    \n",
    "    def write_simple_pcd(self, point_3d, filepath, verbose = False):\n",
    "        \"\"\" \n",
    "        Saves 3D points which can be read in read in meshlab\n",
    "        \"\"\"\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utilty.Vector3dVector(point_3d)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(np.zeros_like(point_3d))\n",
    "        \n",
    "        o3d.io.write_point_cloud(filepath, pcd)\n",
    "    \n",
    "    \n",
    "    def detect_and_match_feature(self, img1, img2):\n",
    "        start = time.time()\n",
    "        sift = cv2.xfeatures2d.SIFT_create() # create SIFT object\n",
    "        kp1, desc1 = sift.detectAndCompute(img1, None) # Detect keypoints and find descriptors of first image\n",
    "        start1 = time.time()\n",
    "        kp2, desc2 = sift.detectAndCompute(img2, None)\n",
    "        print(np.shape(desc1))\n",
    "        print(np.shape(desc2))\n",
    "        \n",
    "        \n",
    "        start2 = time.time()\n",
    "        start4 = time.time()\n",
    "        matches = KNNMatch(desc1, desc2, k = 2)\n",
    "        \n",
    "        elapsed2 = time.time() - start4\n",
    "        print(\"Time for detect and match feature description {}\".format(elapsed2))\n",
    "        \n",
    "        matches_good = []\n",
    "        \n",
    "        start3 = time.time()\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.7 * n.distance: # Peform ratio test to select good feature matches\n",
    "                matches_good.append(m)\n",
    "        elapsed3 = time.time() - start3\n",
    "        \n",
    "        p1 = np.float32([kp1[m.queryIdx].pt for m in matches_good]).reshape(-1, 1, 2)  # descriptors that pass ratio test\n",
    "        p2 = np.float32([kp2[m.trainIdx].pt for m in matches_good]).reshape(-1, 1, 2)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return p1, p2, matches_good, kp1, kp2\n",
    "    \n",
    "    def compute_essential(self, p1, p2):\n",
    "        start = time.time()\n",
    "        E, mask = cv2.findEssentialMat(p1, p2, self.intrinsic)  # Find essential matrix\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return E, mask\n",
    "    \n",
    "    \n",
    "    def compute_pose(self, p1, p2, E):\n",
    "        start = time.time()\n",
    "        retval, R, trans, mask = cv2.recoverPose(E, p1, p2, self.intrinsic)  # recovered relative rotation and translation given essential matrix and p1, p2\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        return R, trans\n",
    "    \n",
    "    def triangulate(self, p1, p2, R, trans, mask):\n",
    "        \n",
    "        start = time.time()\n",
    "        matchesMask = mask.ravel().tolist() # Use mask to remove outliers\n",
    "        p1 = p1[np.array(matchesMask)== 1, : , :]\n",
    "        p2 = p2[np.array(matchesMask)== 1, :, :]\n",
    "        \n",
    "        P1 = cv2.undistortPoints(p1, self.intrinsic, None) # Convert image coords to normalized coords for first image\n",
    "        P2 = cv2.undistortPoints(p2, self.intrinsic, None)\n",
    "        \n",
    "        I = np.identity(3) # Rotation of first camera. Identity as origin is at first camera\n",
    "        z = np.zeros((3, 1)) # Translation of first camera. Zero as origin is at first camera\n",
    "        \n",
    "        projMatr1 = np.concatenate((I, z), axis = 1) # Calculate matrix of extrinsic parameters( [R t]) of first camera\n",
    "        \n",
    "        projMatr2 = np.concatenate((R, trans), axis = 1) # Calculate matrix of extrinsic parameter ([ R t]) of second camera\n",
    "        \n",
    "        points_4d_hom = cv2.triangulatePoints(projMatr1, projMatr2, P1, P2) # Homogeneous coordinate\n",
    "        \n",
    "        points_4d = points_4d_hom / np.tile(points_4d_hom[-1, :], (4, 1))\n",
    "        points_3d = points_4d[:3, :].T # Take first three coordinates (3D points)\n",
    "        \n",
    "        elapsed = time.time()\n",
    "        \n",
    "        return points_3d\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        self.load_images()\n",
    "        \n",
    "        # pair processing\n",
    "        \n",
    "        # step1 and 2 : detect and match feature\n",
    "        p1, p2, matches_good, kp1, kp2 = self.detect_and_match_feature(\n",
    "            self.imgs[1], self.imgs[2]\n",
    "        )\n",
    "        \n",
    "        self.visualize_matche(\n",
    "            self.imgs[1], self.imgs[2], kp1, kp2, matches_good,\n",
    "            save_path = join(self.output_dir, 'sift_match_01_7.png')\n",
    "        )\n",
    "        \n",
    "        # step3: compute essential matrix\n",
    "        E, mask = self.compute_essential(p1, p2)\n",
    "        \n",
    "        self.visualize_matches(\n",
    "            self.imgs[1], self.imgs[2], kp1, kp2, matches_good, mask = mask,\n",
    "            save_path=join(self.output_dir, 'inlier_match_01_7.png')\n",
    "        )\n",
    "        \n",
    "        self.visualize_epipolar_lines(\n",
    "            self.imgs[1], self.imgs[2], p1, p2, E,\n",
    "            save_path = join(self.output_dir, 'epipolar_lines_01_7.png')\n",
    "        )\n",
    "        \n",
    "        # Step 4: recover pose\n",
    "        R, trans = self.compute_pose(p1, p2, E)\n",
    "        # step 5: Triangulation\n",
    "        point_3d = self.triangulate(p1, p2, R, trans, mask)\n",
    "        \n",
    "        self.write_simple_pcd(point_3d, join(self.output_dir, 'temple1.pcd'))\n",
    "        \n",
    "    \n",
    "def safe_mkdir(file_dir):\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.mkdir(file_dir)\n",
    "\n",
    "def intrinsic_reader(txt_file):\n",
    "    with open(txt_file) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    return np.array(\n",
    "        [l.strip(' ') for l in lines], \n",
    "        dtype = np.float32\n",
    "    )\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c63813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    img_pattern = \"\"\n",
    "    intrinsic = \"\"\n",
    "    output_dir = './output'\n",
    "    safe_mkdir(output_dir)\n",
    "    \n",
    "    sfm_solver = SfMSolver(img_pattern, intrinsic, output_dir, downscale = 2)\n",
    "    sfm_solver.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d55512",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a38726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd_path = \"output/temple1.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
